{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X4-kKK_1yPx"
      },
      "source": [
        "## Clone Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1cDHVEb1uOh",
        "outputId": "78d1bcfc-8dee-4da5-9e70-cf3ba7f7b7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Adversarial-Representation-Learning-for-Medical-Imaging'...\n",
            "remote: Enumerating objects: 523, done.\u001b[K\n",
            "remote: Counting objects: 100% (523/523), done.\u001b[K\n",
            "remote: Compressing objects: 100% (373/373), done.\u001b[K\n",
            "remote: Total 523 (delta 300), reused 357 (delta 138), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (523/523), 49.64 MiB | 14.04 MiB/s, done.\n",
            "Resolving deltas: 100% (300/300), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo\n",
        "!git clone https://<DRIVE>@github.com/java-master007/Adversarial-Representation-Learning-for-Medical-Imaging.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UgmJZbs11J7",
        "outputId": "356c0e3e-f76b-4bff-c1b8-24846b845ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging\n"
          ]
        }
      ],
      "source": [
        "# Change to the correct directory\n",
        "%cd Adversarial-Representation-Learning-for-Medical-Imaging/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vab1bbrK13JC"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "# It will need restart on colab\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-EZvBH-LlrR"
      },
      "source": [
        "## Image Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNiTcN3w6pq"
      },
      "source": [
        "Requires that:\n",
        "- malign.png be 3-channel\n",
        "- normal.png be 3-channel\n",
        "- malign_mask.png be one-channel (BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KFcbV3kZcJih"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io as img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import torchvision as tv\n",
        "from PIL import Image, ImageDraw, ImageFilter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_laterality(image):\n",
        "    left_edge = np.sum(image[:, 0])  \n",
        "    right_edge = np.sum(image[:, -1])\n",
        "    return (True, False) if left_edge < right_edge else (False, True)"
      ],
      "metadata": {
        "id": "CXoEsj5DDRTx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_measures(image):\n",
        "    positions = np.nonzero(image)\n",
        "    top = positions[0].min()\n",
        "    bottom = positions[0].max()\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    return top, right, bottom, left"
      ],
      "metadata": {
        "id": "PdQW6pLMDSnn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_start_coordinate(image, mass_path, laterality_r):\n",
        "    imag = cv2.imread(mass_path, cv2.IMREAD_UNCHANGED)\n",
        "    positions = np.nonzero(image)\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    vertical_co = positions[0][list(positions[1]).index(left)]\n",
        "    vertical_co_r = positions[0][list(positions[1]).index(right)]\n",
        "\n",
        "    if laterality_r:\n",
        "        return left, int(vertical_co-imag.shape[1]/2)\n",
        "    else:\n",
        "        return right, int(vertical_co_r-imag.shape[1]/2)"
      ],
      "metadata": {
        "id": "_W5Yy675DVJ2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_correct_value(number):\n",
        "    if number == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "mXNqcyeaDWew"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_binary(image, pth):\n",
        "    b_image = []\n",
        "    for arr in image:\n",
        "        curr = [get_correct_value(elem) for elem in arr]\n",
        "        b_image.append(curr)\n",
        "    b_image = np.array(b_image, dtype=np.uint8)\n",
        "\n",
        "    plt.imsave(pth, np.array(b_image), cmap=cm.gray)\n",
        "    return b_image"
      ],
      "metadata": {
        "id": "kuQQcIOdDXc_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def does_collage_mask(width, height, normal):\n",
        "\n",
        "    normal_image = Image.open(normal)\n",
        "    mass_to_paste = Image.open('/content/malign_aux.png')\n",
        "\n",
        "    # Creates collage and save\n",
        "    back_im = normal_image.copy()\n",
        "    back_im.paste(mass_to_paste, (width,height), mass_to_paste)\n",
        "    \n",
        "    return list(back_im.getdata()) == list(normal_image.getdata())"
      ],
      "metadata": {
        "id": "RKbP8PApDcPh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_collage_possible(malign_mask_pth, normal_breast_pth):\n",
        "\n",
        "  # Operations Threshold\n",
        "  threshold = 50\n",
        "\n",
        "  # Read the images\n",
        "  malign_mask = cv2.imread(malign_mask_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  normal_breast = cv2.imread(normal_breast_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  _, normal_x = normal_breast.shape\n",
        "  normal_breast = image_to_binary(normal_breast, '/content/normal_aux.png')\n",
        "\n",
        "  # Get images laterality\n",
        "  R, _ = get_image_laterality(normal_breast)\n",
        "\n",
        "  # Get images measures\n",
        "  # Calculate malign mass measures\n",
        "  m_top, m_right, m_bottom, m_left = get_measures(malign_mask)\n",
        "\n",
        "  # Calculate normal breast measures\n",
        "  n_top, n_right, n_bottom, n_left = get_measures(normal_breast)\n",
        "\n",
        "  # Calculate widths and heights\n",
        "  malign_mass_width = abs(m_right-m_left)\n",
        "  malign_mass_height = abs(m_bottom-m_top)\n",
        "  normal_breast_width = abs(n_right-n_left)\n",
        "  normal_breast_height = abs(n_bottom-n_top)\n",
        "\n",
        "  # Check if its worth the try\n",
        "  if malign_mass_width > normal_breast_width or malign_mass_height > normal_breast_height:\n",
        "    return -1, -1\n",
        "\n",
        "  # Crop the malign mask\n",
        "  crop_segmentation(malign_mask_pth, '/content/malign_aux.png')\n",
        "\n",
        "  # Get bottom base coordinate\n",
        "  base_coordinate = get_start_coordinate(normal_breast, '/content/malign_aux.png', R)\n",
        "\n",
        "  # Coordinate collage starts bottom\n",
        "  c, d = base_coordinate\n",
        "\n",
        "  if R:\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while c < normal_breast.shape[0]:\n",
        "      if does_collage_mask(c, d, '/content/normal_aux.png'):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c+threshold, d\n",
        "\n",
        "    return -1, -1\n",
        "  else:\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while c > 0:\n",
        "      if does_collage_mask(c, d, '/content/normal_aux.png'):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c-threshold, d\n",
        "\n",
        "    return -1, -1"
      ],
      "metadata": {
        "id": "GtPk4p5gDiBj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7EvfVGz8cK37"
      },
      "outputs": [],
      "source": [
        "# Remove the 4 channel to collage image\n",
        "def remove_4_channel(im_path, output_path):\n",
        "\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    # Transpose naive image to properly see it\n",
        "    tranposed = img.transpose(2,0,1)\n",
        "\n",
        "    # Transpose image again with only the 3 rgb channels to save\n",
        "    output = tranposed[0:3].transpose(1,2,0)\n",
        "\n",
        "    # Save new naive image (3-channels)\n",
        "    cv2.imwrite(output_path, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PGT3kdfwcNzb"
      },
      "outputs": [],
      "source": [
        "# Resize image for hamronisation\n",
        "def resize_image(im_path, percent_original, output_path):\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "    \n",
        "    print('Original Dimensions : ',img.shape)\n",
        "    \n",
        "    scale_percent = percent_original # percent of original size\n",
        "    width = int(img.shape[1] * scale_percent / 100)\n",
        "    height = int(img.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    \n",
        "    # resize image\n",
        "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    print('Resized Dimensions : ',resized.shape)\n",
        "    cv2.imwrite(output_path, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2TkjI3EXcMVq"
      },
      "outputs": [],
      "source": [
        "# Make mask have 3 channels\n",
        "def make_3_channels_mask(im_path, out_path):\n",
        "  i = img.imread(im_path)\n",
        "  new_i = []\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i = torch.tensor(np.array(new_i))\n",
        "  tv.io.write_png(new_i, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bZX9tjIyXxmQ"
      },
      "outputs": [],
      "source": [
        "# Crops the segmentation by its limits\n",
        "def crop_segmentation(fp, outp):\n",
        "  imag = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
        "  imageObject = Image.open(fp)\n",
        "  positions = np.nonzero(imag)\n",
        "\n",
        "  top = positions[0].min()\n",
        "  bottom = positions[0].max()\n",
        "  left = positions[1].min()\n",
        "  right = positions[1].max()\n",
        "\n",
        "  cropped = imageObject.crop((left,top,right,bottom))\n",
        "  cropped.save(outp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pk4uvtD9T-Kz"
      },
      "outputs": [],
      "source": [
        "# Makes a collage given the malign image, the malign mask, and the normal image\n",
        "def make_collage(malign_pth, malign_mask_pth, normal_pth, width, height):\n",
        "\n",
        "  # Reads malign base image\n",
        "  malign = cv2.imread(malign_pth, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Convert mask to 3 channels\n",
        "  make_3_channels_mask(malign_mask_pth, '/content/malign_mask3.png')\n",
        "  malign_mask = cv2.imread('/content/malign_mask3.png', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Grab the image mask from the mass image\n",
        "  masked = malign.copy()\n",
        "  masked[malign_mask == 0] = 0\n",
        "  cv2.imwrite('/content/segmented_mass.png', masked)\n",
        "\n",
        "  # Crop both the mask, and the masked mass\n",
        "  crop_segmentation('/content/segmented_mass.png', '/content/cropped_mass.png')\n",
        "  crop_segmentation(malign_mask_pth, '/content/malign_mask_cropped.png')\n",
        "\n",
        "  normal_image = Image.open(normal_pth)\n",
        "  mass_to_paste = Image.open('/content/cropped_mass.png')\n",
        "  mass_mask = Image.open('/content/malign_mask_cropped.png')\n",
        "\n",
        "  # Creates collage and save\n",
        "  back_im = normal_image.copy()\n",
        "  back_im.paste(mass_to_paste, (width,height), mass_mask)\n",
        "  back_im.save('/content/collage.png', quality=95)\n",
        "\n",
        "  # Creates collage mask\n",
        "  collage_mask = Image.new(\"L\", back_im.size, 0)\n",
        "  collage_mask.paste(mass_mask, (width,height))\n",
        "  collage_mask.save('/content/collage_mask.png', quality=95)\n",
        "\n",
        "  # Deletes unecessary images\n",
        "  try:\n",
        "    os.remove('/content/malign_mask3.png')\n",
        "    os.remove('/content/segmented_mass.png')\n",
        "    os.remove('/content/cropped_mass.png')\n",
        "    os.remove('/content/malign_mask_cropped.png')\n",
        "  except OSError as e:\n",
        "    print(f\"FAILED\\nFile: {e.filename}\\nError: {e.strerror}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, h = is_collage_possible(malign_mask_pth='/content/malign_mask.png', normal_breast_pth='/content/normal.png')\n",
        "w, h"
      ],
      "metadata": {
        "id": "TBlMM1JrWLb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f99997-aae5-41ad-9540-931ae2a6f225"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048, 997)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RKsyHncdbqI9"
      },
      "outputs": [],
      "source": [
        "make_collage(malign_pth='/content/malign.png', malign_mask_pth='/content/malign_mask.png', normal_pth='/content/normal.png', width=w, height=h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHsKlSIk1_-6"
      },
      "source": [
        "## Harmonizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcUgsHrZ1CMK"
      },
      "source": [
        "### Harmonzer Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R5F5Tzc2qdB",
        "outputId": "bf640b89-fca2-4717-960a-8a7571519101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN\n"
          ]
        }
      ],
      "source": [
        "# Change to correct directory\n",
        "%cd MedSinGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fgEKbQamS5c"
      },
      "outputs": [],
      "source": [
        "# Make the collage mask 3-channel\n",
        "make_3_channels_mask('/content/collage_mask.png', '/content/collage_mask3.png')\n",
        "os.remove('/content/collage_mask.png')\n",
        "os.rename('/content/collage_mask3.png', '/content/collage_mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGuzzV6l2BIZ"
      },
      "outputs": [],
      "source": [
        "# Normal breast collage Harmonizer creation\n",
        "!python main_train.py --train_mode harmonization --gpu 0 --train_stages 3 --im_min_size 480 --lrelu_alpha 0.3 --niter 1000 --batch_norm --input_name /content/normal.png --naive_img /content/collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMNlBMrG1Hmg"
      },
      "source": [
        "### Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jx-vpMU5osX"
      },
      "outputs": [],
      "source": [
        "# Get the latest model\n",
        "def get_latest_model():\n",
        "  base_path = \"TrainedModels/normal/\"\n",
        "  models = os.listdir(base_path)\n",
        "\n",
        "  latest = 0 # Values will always be bigger than 0\n",
        "  desired = models[0]\n",
        "\n",
        "  for id, model in enumerate(models):\n",
        "    splitted = model.split(\"_\")\n",
        "    code = splitted[:6]\n",
        "    code = int(''.join(code))\n",
        "    if code > latest:\n",
        "      latest = code\n",
        "      desired = model\n",
        "\n",
        "  return os.path.join(base_path, desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AacGNG07vBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72718011-b810-481e-d248-637450fd0ac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# FINE TUNE\n",
        "m = get_latest_model()\n",
        "fine_tune_cmd = \"python main_train.py --gpu 0 --train_mode harmonization --input_name /content/normal.png --naive_img /content/collage.png --fine_tune --model_dir \" + str(m)\n",
        "os.system(fine_tune_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBaDW1M0gG7u"
      },
      "outputs": [],
      "source": [
        "# FINE TUNE\n",
        "# !python main_train.py --gpu 0 --train_mode harmonization --input_name /content/normal.png --naive_img /content/collage.png --fine_tune --model_dir TrainedModels/normal/2022_01_17_19_51_18_harmonization_niter_1000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjOZzo8S18Z7"
      },
      "source": [
        "### Harmonise The Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WbYrgQoBdzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23415551-ddc1-4140-a84b-add6ea3ff37d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Normal breast collage harmonisation\n",
        "m = get_latest_model()\n",
        "harmonise_cmd = \"python evaluate_model.py --gpu 0 --model_dir \" + str(m) + \" --naive_img /content/collage.png\"\n",
        "os.system(harmonise_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR3plhis-83m"
      },
      "outputs": [],
      "source": [
        "# Normal breast collage harmonisation\n",
        "#!python evaluate_model.py --gpu 0 --model_dir TrainedModels/normal/2022_01_17_21_07_38_harmonization_fine-tune_niter_2000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 --naive_img /content/collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBSXbWo5A-Ck"
      },
      "source": [
        "### Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNBvrMZ8DYaG"
      },
      "outputs": [],
      "source": [
        "# Resizes an image to a specific dimension\n",
        "def resize_to_dim(img_pth, width, height, out_pth):\n",
        "  base = cv2.imread(img_pth, cv2.IMREAD_UNCHANGED)\n",
        "  dim = (width, height)\n",
        "  resized = cv2.resize(base, dim)\n",
        "  cv2.imwrite(out_pth, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6zP9J5ZD8sP"
      },
      "outputs": [],
      "source": [
        "resize_to_dim('/content/normal.png', 204, 250, '/content/normal_resized.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "2a7cfb765b484d838004288df4e56616",
            "73bfc6d441d1464fb9186eee19ff5bf9",
            "72bafa0d73854b21bcdf29689461c762",
            "efabe55bd5384238ab7881f8440fca17",
            "0a2c8e7953da4bbfbc763870a3f29ffa",
            "8ec63a6480634ab781245b0cc54a8277",
            "40b02248fed44878a62f5df03d81f2dd",
            "9d4ee22a37274c6ab07de2b37e78d913",
            "9b09359b01dc4fcdb1d982819cf2cdd3",
            "6d261f347de84804aa1073adc0b10c18",
            "aca5cbe332c7462c8b4218ebe22096d9",
            "a60f8a9bffae495da9023e6acedb9280",
            "bbc13fbfb11d49f3b8969f0d99b72979",
            "4d73119a728341b8b887222fec9fe88b",
            "b06bef4ecd9a481d916cd1b4129d5eba",
            "bdf610b2ad744311a7fe62dc07aaffb8",
            "f9a43100320748fc98944e8748d1d3b2",
            "453cc836932c46a08dbf861e2255c999",
            "404b7f5fc2a44bb594551d9c8c620673",
            "c2f02b13901e463182b4737d24f9966c",
            "116e679aab594ebb8b23d8a8172067ff",
            "a1a40f70061f452489f810ff1b67489d"
          ]
        },
        "id": "5YlWVtyXBAU8",
        "outputId": "d75f9c1f-45f3-4e19-a955-96878a254477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a7cfb765b484d838004288df4e56616",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/richzhang/PerceptualSimilarity/raw/master/lpips/weights/v0.1/alex.pth\" to /root/.cache/torch/hub/checkpoints/alex.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a60f8a9bffae495da9023e6acedb9280",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/5.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LPIPS: 0.09767814725637436\n",
            "SSIM: 0.8905271887779236\n",
            "MS-SSIM: 0.9178247451782227\n"
          ]
        }
      ],
      "source": [
        "import evaluate_generation\n",
        "\n",
        "base_img = '/content/normal_resized.png'\n",
        "eval_folder = os.path.join(get_latest_model(),'Evaluation_/content/collage.png')\n",
        "\n",
        "evaluator = evaluate_generation.GenerationEvaluator(base_img, eval_folder)\n",
        "\n",
        "lpips = evaluator.run_lpips()\n",
        "ssim, ms_ssim = evaluator.run_mssim()\n",
        "print(f\"LPIPS: {lpips}\\nSSIM: {ssim}\\nMS-SSIM: {ms_ssim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ds0KPgz6uI-"
      },
      "source": [
        "## Save Harmonizer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZS5yU5U6vkU"
      },
      "outputs": [],
      "source": [
        "# Import files to download zips\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTxipCzy60ge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "74372ce4-cf0d-4a01-cb58-8c72ff292b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/meta.yaml (deflated 17%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Generator Train Loss Reconstruction (deflated 54%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Discriminator Train Loss Gradient Penalty (deflated 55%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Generator Train Loss (deflated 53%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Discriminator Train Loss Real (deflated 53%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Discriminator Train Loss Fake (deflated 52%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/artifacts/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/meta.yaml (deflated 41%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.user (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.source.git.commit (deflated 3%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.source.name (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/Train Depth (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/Learning Scale Rate (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/Activation Function (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/N Training Stages (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/N Iterations (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/.trash/ (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d9a99dd9-1a69-43d3-8d7a-1773452a9f7d\", \"mlrun.zip\", 11484)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip the mlruns metrics to analyse\n",
        "!zip -r /content/mlrun.zip /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns\n",
        "files.download(\"/content/mlrun.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "o-IZgTDG610d",
        "outputId": "e9c39899-bf33-40f2-a379-c67b87fb8a8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0d7569a6-f3e8-4f99-966c-77ef7475cc95\", \"best_harmonisation_model.zip\", 111599141)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip the best model analysed based on the mlruns\n",
        "m = get_latest_model()\n",
        "zip_cmd = \"zip -r /content/best_harmonisation_model.zip \" + str(m)\n",
        "os.system(zip_cmd)\n",
        "files.download(\"/content/best_harmonisation_model.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fEUmlAKc7zn"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tip34yzOc8Yo"
      },
      "outputs": [],
      "source": [
        "# Remove the MLFlow runs\n",
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RydIJkA9dDav"
      },
      "outputs": [],
      "source": [
        "# Remove all trained models\n",
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/TrainedModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-YrF4bB_dFAz"
      },
      "outputs": [],
      "source": [
        "# Remove all images\n",
        "! find . -name \"*.png\" -type f -delete"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TcjWDV8lbgXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9X4-kKK_1yPx",
        "dHsKlSIk1_-6",
        "QMNlBMrG1Hmg",
        "0fEUmlAKc7zn"
      ],
      "name": "Harmonisation Baseline Model - ConSinGAN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a7cfb765b484d838004288df4e56616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73bfc6d441d1464fb9186eee19ff5bf9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72bafa0d73854b21bcdf29689461c762",
              "IPY_MODEL_efabe55bd5384238ab7881f8440fca17",
              "IPY_MODEL_0a2c8e7953da4bbfbc763870a3f29ffa"
            ]
          }
        },
        "73bfc6d441d1464fb9186eee19ff5bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72bafa0d73854b21bcdf29689461c762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ec63a6480634ab781245b0cc54a8277",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40b02248fed44878a62f5df03d81f2dd"
          }
        },
        "efabe55bd5384238ab7881f8440fca17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d4ee22a37274c6ab07de2b37e78d913",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244408911,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244408911,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b09359b01dc4fcdb1d982819cf2cdd3"
          }
        },
        "0a2c8e7953da4bbfbc763870a3f29ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d261f347de84804aa1073adc0b10c18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:06&lt;00:00, 47.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aca5cbe332c7462c8b4218ebe22096d9"
          }
        },
        "8ec63a6480634ab781245b0cc54a8277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40b02248fed44878a62f5df03d81f2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d4ee22a37274c6ab07de2b37e78d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b09359b01dc4fcdb1d982819cf2cdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d261f347de84804aa1073adc0b10c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aca5cbe332c7462c8b4218ebe22096d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a60f8a9bffae495da9023e6acedb9280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bbc13fbfb11d49f3b8969f0d99b72979",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d73119a728341b8b887222fec9fe88b",
              "IPY_MODEL_b06bef4ecd9a481d916cd1b4129d5eba",
              "IPY_MODEL_bdf610b2ad744311a7fe62dc07aaffb8"
            ]
          }
        },
        "bbc13fbfb11d49f3b8969f0d99b72979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d73119a728341b8b887222fec9fe88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9a43100320748fc98944e8748d1d3b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_453cc836932c46a08dbf861e2255c999"
          }
        },
        "b06bef4ecd9a481d916cd1b4129d5eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_404b7f5fc2a44bb594551d9c8c620673",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6009,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6009,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2f02b13901e463182b4737d24f9966c"
          }
        },
        "bdf610b2ad744311a7fe62dc07aaffb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_116e679aab594ebb8b23d8a8172067ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.87k/5.87k [00:00&lt;00:00, 159kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1a40f70061f452489f810ff1b67489d"
          }
        },
        "f9a43100320748fc98944e8748d1d3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "453cc836932c46a08dbf861e2255c999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "404b7f5fc2a44bb594551d9c8c620673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2f02b13901e463182b4737d24f9966c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "116e679aab594ebb8b23d8a8172067ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1a40f70061f452489f810ff1b67489d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}