{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X4-kKK_1yPx"
      },
      "source": [
        "## Clone Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1cDHVEb1uOh",
        "outputId": "da908bc0-ec09-4352-9017-a00e03cae7b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Adversarial-Representation-Learning-for-Medical-Imaging'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (499/499), done.\u001b[K\n",
            "remote: Compressing objects: 100% (353/353), done.\u001b[K\n",
            "remote: Total 499 (delta 286), reused 343 (delta 134), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (499/499), 49.62 MiB | 12.27 MiB/s, done.\n",
            "Resolving deltas: 100% (286/286), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo\n",
        "!git clone https://<DRIVE>@github.com/java-master007/Adversarial-Representation-Learning-for-Medical-Imaging.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UgmJZbs11J7",
        "outputId": "83beb508-0466-453d-faa0-13f9912bc602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging\n"
          ]
        }
      ],
      "source": [
        "# Change to the correct directory\n",
        "%cd Adversarial-Representation-Learning-for-Medical-Imaging/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vab1bbrK13JC"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "# It will need restart on colab\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-EZvBH-LlrR"
      },
      "source": [
        "## Image Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNiTcN3w6pq"
      },
      "source": [
        "Requires that:\n",
        "- malign.png be 3-channel\n",
        "- normal.png be 3-channel\n",
        "- malign_mask.png be one-channel (BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFcbV3kZcJih"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io as img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import torchvision as tv\n",
        "from PIL import Image, ImageDraw, ImageFilter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_laterality(image):\n",
        "    left_edge = np.sum(image[:, 0])  \n",
        "    right_edge = np.sum(image[:, -1])\n",
        "    return (True, False) if left_edge < right_edge else (False, True)"
      ],
      "metadata": {
        "id": "CXoEsj5DDRTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_measures(image):\n",
        "    positions = np.nonzero(image)\n",
        "    top = positions[0].min()\n",
        "    bottom = positions[0].max()\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    return top, right, bottom, left"
      ],
      "metadata": {
        "id": "PdQW6pLMDSnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_start_coordinate(image):\n",
        "    positions = np.nonzero(image)\n",
        "    bottom = positions[0].max()\n",
        "    x_bottom = int(np.mean(np.nonzero(image[bottom])))\n",
        "    return x_bottom, bottom"
      ],
      "metadata": {
        "id": "_W5Yy675DVJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_correct_value(number):\n",
        "    if number == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "mXNqcyeaDWew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_binary(image, pth):\n",
        "    b_image = []\n",
        "    for arr in image:\n",
        "        curr = [get_correct_value(elem) for elem in arr]\n",
        "        b_image.append(curr)\n",
        "    b_image = np.array(b_image, dtype=np.uint8)\n",
        "\n",
        "    os.remove(pth)\n",
        "    plt.imsave(pth, np.array(b_image), cmap=cm.gray)\n",
        "    return b_image"
      ],
      "metadata": {
        "id": "kuQQcIOdDXc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def does_collage_mask(width, height, malign, normal):\n",
        "    \n",
        "    # Crop both the mass, and the normal\n",
        "    crop_segmentation(malign, 'malign_aux.png')\n",
        "\n",
        "    normal_image = Image.open(normal)\n",
        "    mass_to_paste = Image.open('malign_aux.png')\n",
        "\n",
        "    # Creates collage and save\n",
        "    back_im = normal_image.copy()\n",
        "    back_im.paste(mass_to_paste, (width,height), mass_to_paste)\n",
        "    \n",
        "    return list(back_im.getdata()) == list(normal_image.getdata())"
      ],
      "metadata": {
        "id": "RKbP8PApDcPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_collage_possible(malign_mask_pth, normal_breast_pth):\n",
        "\n",
        "  # Operations Threshold\n",
        "  threshold = 50\n",
        "\n",
        "  # Read the images\n",
        "  malign_mask = cv2.imread(malign_mask_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  normal_breast = cv2.imread(normal_breast_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  _, normal_x = normal_breast.shape\n",
        "  normal_breast = image_to_binary(normal_breast, normal_breast_pth)\n",
        "\n",
        "  # Get images laterality\n",
        "  R, _ = get_image_laterality(normal_breast)\n",
        "\n",
        "  # Get images measures\n",
        "  # Calculate malign mass measures\n",
        "  m_top, m_right, m_bottom, m_left = get_measures(malign_mask)\n",
        "\n",
        "  # Calculate normal breast measures\n",
        "  n_top, n_right, n_bottom, n_left = get_measures(normal_breast)\n",
        "\n",
        "  # Calculate widths and heights\n",
        "  malign_mass_width = abs(m_right-m_left)\n",
        "  malign_mass_height = abs(m_bottom-m_top)\n",
        "  normal_breast_width = abs(n_right-n_left)\n",
        "  normal_breast_height = abs(n_bottom-n_top)\n",
        "\n",
        "  # Check if its worth the try\n",
        "  if malign_mass_width > normal_breast_width or malign_mass_height > normal_breast_height:\n",
        "    return -1, -1\n",
        "\n",
        "  # Get bottom base coordinate\n",
        "  bottom_coordinate = get_start_coordinate(normal_breast)\n",
        "\n",
        "  # Coordinate collage starts bottom\n",
        "  c, d = bottom_coordinate\n",
        "\n",
        "  if R:\n",
        "\n",
        "    # Check if mass is all inside image. If not, then go left + threshold\n",
        "    if normal_x - c < malign_mass_width:\n",
        "      c, d = c-(malign_mass_width-(normal_x - c)+threshold), d\n",
        "\n",
        "    # Go up the height plus the threshold\n",
        "    c, d = c, d-(malign_mass_height+threshold)\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while d > threshold:\n",
        "      if does_collage_mask(c, d, malign_mask_pth, normal_breast_pth):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c, d-threshold\n",
        "\n",
        "    return -1, -1\n",
        "  else:\n",
        "    \n",
        "    # Check if mass is all inside image. If not, then go right + threshold\n",
        "    if c < malign_mass_width:\n",
        "      c, d = c+(malign_mass_width-c+threshold), d\n",
        "\n",
        "    # Go up the height plus the threshold\n",
        "    c, d = c, d-(malign_mass_height+threshold)\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while d > threshold:\n",
        "      if does_collage_mask(c, d, malign_mask_pth, normal_breast_pth):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c, d-threshold\n",
        "\n",
        "    return -1, -1"
      ],
      "metadata": {
        "id": "GtPk4p5gDiBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EvfVGz8cK37"
      },
      "outputs": [],
      "source": [
        "# Remove the 4 channel to collage image\n",
        "def remove_4_channel(im_path, output_path):\n",
        "\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    # Transpose naive image to properly see it\n",
        "    tranposed = img.transpose(2,0,1)\n",
        "\n",
        "    # Transpose image again with only the 3 rgb channels to save\n",
        "    output = tranposed[0:3].transpose(1,2,0)\n",
        "\n",
        "    # Save new naive image (3-channels)\n",
        "    cv2.imwrite(output_path, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGT3kdfwcNzb"
      },
      "outputs": [],
      "source": [
        "# Resize image for hamronisation\n",
        "def resize_image(im_path, percent_original, output_path):\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "    \n",
        "    print('Original Dimensions : ',img.shape)\n",
        "    \n",
        "    scale_percent = percent_original # percent of original size\n",
        "    width = int(img.shape[1] * scale_percent / 100)\n",
        "    height = int(img.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    \n",
        "    # resize image\n",
        "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    print('Resized Dimensions : ',resized.shape)\n",
        "    cv2.imwrite(output_path, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TkjI3EXcMVq"
      },
      "outputs": [],
      "source": [
        "# Make mask have 3 channels\n",
        "def make_3_channels_mask(im_path, out_path):\n",
        "  i = img.imread(im_path)\n",
        "  new_i = []\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i = torch.tensor(np.array(new_i))\n",
        "  tv.io.write_png(new_i, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZX9tjIyXxmQ"
      },
      "outputs": [],
      "source": [
        "# Crops the segmentation by its limits\n",
        "def crop_segmentation(fp, outp):\n",
        "  imag = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
        "  imageObject = Image.open(fp)\n",
        "  positions = np.nonzero(imag)\n",
        "\n",
        "  top = positions[0].min()\n",
        "  bottom = positions[0].max()\n",
        "  left = positions[1].min()\n",
        "  right = positions[1].max()\n",
        "\n",
        "  cropped = imageObject.crop((left,top,right,bottom))\n",
        "  cropped.save(outp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk4uvtD9T-Kz"
      },
      "outputs": [],
      "source": [
        "# Makes a collage given the malign image, the malign mask, and the normal image\n",
        "def make_collage(malign_pth, malign_mask_pth, normal_pth, width, height):\n",
        "\n",
        "  # Reads malign base image\n",
        "  malign = cv2.imread(malign_pth, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Convert mask to 3 channels\n",
        "  make_3_channels_mask(malign_mask_pth, '/content/malign_mask3.png')\n",
        "  malign_mask = cv2.imread('/content/malign_mask3.png', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Grab the image mask from the mass image\n",
        "  masked = malign.copy()\n",
        "  masked[malign_mask == 0] = 0\n",
        "  cv2.imwrite('/content/segmented_mass.png', masked)\n",
        "\n",
        "  # Crop both the mask, and the masked mass\n",
        "  crop_segmentation('/content/segmented_mass.png', '/content/cropped_mass.png')\n",
        "  crop_segmentation(malign_mask_pth, '/content/malign_mask_cropped.png')\n",
        "\n",
        "  normal_image = Image.open(normal_pth)\n",
        "  mass_to_paste = Image.open('/content/cropped_mass.png')\n",
        "  mass_mask = Image.open('/content/malign_mask_cropped.png')\n",
        "\n",
        "  # Creates collage and save\n",
        "  back_im = normal_image.copy()\n",
        "  #TODO: Calculate how to paste\n",
        "  back_im.paste(mass_to_paste, (width,height), mass_mask)\n",
        "  back_im.save('/content/collage.png', quality=95)\n",
        "\n",
        "  # Creates collage mask\n",
        "  collage_mask = Image.new(\"L\", back_im.size, 0)\n",
        "  collage_mask.paste(mass_mask, (width,height))\n",
        "  collage_mask.save('/content/collage_mask.png', quality=95)\n",
        "\n",
        "  # Deletes unecessary images\n",
        "  try:\n",
        "    os.remove('/content/malign_mask3.png')\n",
        "    os.remove('/content/segmented_mass.png')\n",
        "    os.remove('/content/cropped_mass.png')\n",
        "    os.remove('/content/malign_mask_cropped.png')\n",
        "  except OSError as e:\n",
        "    print(f\"FAILED\\nFile: {e.filename}\\nError: {e.strerror}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, h = is_collage_possible(malign_mask_pth='malign_mask.png', normal_breast_pth='normal.png')\n",
        "w, h"
      ],
      "metadata": {
        "id": "TBlMM1JrWLb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_collage, h_collage = is_collage_possible('/content/malign_mask.png', '/content/normal.png')"
      ],
      "metadata": {
        "id": "gjBM0cBrVgL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKsyHncdbqI9"
      },
      "outputs": [],
      "source": [
        "make_collage(malign_pth='/content/malign.png', malign_mask_pth='/content/malign_mask.png', normal_pth='/content/normal.png', width=1000, height=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHsKlSIk1_-6"
      },
      "source": [
        "## Harmonizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcUgsHrZ1CMK"
      },
      "source": [
        "### Harmonzer Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R5F5Tzc2qdB",
        "outputId": "dd975fc0-ce38-42ba-d2fe-951f0bf464b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN\n"
          ]
        }
      ],
      "source": [
        "# Change to correct directory\n",
        "%cd MedSinGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fgEKbQamS5c"
      },
      "outputs": [],
      "source": [
        "# Make the collage mask 3-channel\n",
        "make_3_channels_mask('/content/collage_mask.png', '/content/collage_mask3.png')\n",
        "os.remove('/content/collage_mask.png')\n",
        "os.rename('/content/collage_mask3.png', '/content/collage_mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGuzzV6l2BIZ",
        "outputId": "41faa59a-3901-4b41-f84c-ed21151602e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model (TrainedModels/normal/2022_01_19_14_52_13_harmonization_niter_1000_lr_scale_0.1_nstages_3_BN_act_lrelu_0.3)\n",
            "Training model with the following parameters:\n",
            "\t number of stages: 3\n",
            "\t number of concurrently trained stages: 3\n",
            "\t learning rate scaling: 0.1\n",
            "\t non-linearity: lrelu\n",
            "Training on image pyramid: [torch.Size([1, 3, 31, 25]), torch.Size([1, 3, 149, 121]), torch.Size([1, 3, 720, 585])]\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
            "  FutureWarning,\n",
            "stage [0/2]:: 100% 1000/1000 [00:48<00:00, 20.51it/s]\n",
            "stage [1/2]:: 100% 1000/1000 [10:42<00:00,  1.56it/s]\n",
            "stage [2/2]:: 100% 1000/1000 [1:20:51<00:00,  4.85s/it]\n",
            "Time for training: 5553.907527446747 seconds\n"
          ]
        }
      ],
      "source": [
        "# Normal breast collage Harmonizer creation\n",
        "!python main_train.py --train_mode harmonization --gpu 0 --train_stages 3 --im_max_size 720 --lrelu_alpha 0.3 --niter 1000 --batch_norm --input_name /content/normal.png --naive_img /content/collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMNlBMrG1Hmg"
      },
      "source": [
        "### Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jx-vpMU5osX"
      },
      "outputs": [],
      "source": [
        "# Get the latest model\n",
        "def get_latest_model():\n",
        "  base_path = \"TrainedModels/normal/\"\n",
        "  models = os.listdir(base_path)\n",
        "\n",
        "  latest = 0 # Values will always be bigger than 0\n",
        "  desired = models[0]\n",
        "\n",
        "  for id, model in enumerate(models):\n",
        "    splitted = model.split(\"_\")\n",
        "    code = splitted[:6]\n",
        "    code = int(''.join(code))\n",
        "    if code > latest:\n",
        "      latest = code\n",
        "      desired = model\n",
        "\n",
        "  return os.path.join(base_path, desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AacGNG07vBg"
      },
      "outputs": [],
      "source": [
        "# FINE TUNE\n",
        "m = get_latest_model()\n",
        "fine_tune_cmd = \"python main_train.py --gpu 0 --train_mode harmonization --input_name /content/normal.png --naive_img /content/collage.png --fine_tune --model_dir \" + str(m)\n",
        "os.system(fine_tune_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBaDW1M0gG7u"
      },
      "outputs": [],
      "source": [
        "# FINE TUNE\n",
        "# !python main_train.py --gpu 0 --train_mode harmonization --input_name /content/normal.png --naive_img /content/collage.png --fine_tune --model_dir TrainedModels/normal/2022_01_17_19_51_18_harmonization_niter_1000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjOZzo8S18Z7"
      },
      "source": [
        "### Harmonise The Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WbYrgQoBdzs"
      },
      "outputs": [],
      "source": [
        "# Normal breast collage harmonisation\n",
        "m = get_latest_model()\n",
        "harmonise_cmd = \"python evaluate_model.py --gpu 0 --model_dir \" + str(m) + \" --naive_img /content/collage.png\"\n",
        "os.system(harmonise_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR3plhis-83m",
        "outputId": "708529ac-8e7c-4549-b788-ac8ae0906c59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Normal breast collage harmonisation\n",
        "#!python evaluate_model.py --gpu 0 --model_dir TrainedModels/normal/2022_01_17_21_07_38_harmonization_fine-tune_niter_2000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 --naive_img /content/collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBSXbWo5A-Ck"
      },
      "source": [
        "### Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNBvrMZ8DYaG"
      },
      "outputs": [],
      "source": [
        "# Resizes an image to a specific dimension\n",
        "def resize_to_dim(img_pth, width, height, out_pth):\n",
        "  base = cv2.imread(img_pth, cv2.IMREAD_UNCHANGED)\n",
        "  dim = (width, height)\n",
        "  resized = cv2.resize(base, dim)\n",
        "  cv2.imwrite(out_pth, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6zP9J5ZD8sP"
      },
      "outputs": [],
      "source": [
        "resize_to_dim('/content/normal.png', 204, 250, '/content/normal_resized.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YlWVtyXBAU8",
        "outputId": "19f0d5bd-ef2c-46f4-f5a4-cb60a39fce17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LPIPS: 0.1152394488453865\n",
            "SSIM: 0.8789518475532532\n",
            "MS-SSIM: 0.9195001125335693\n"
          ]
        }
      ],
      "source": [
        "import evaluate_generation\n",
        "\n",
        "base_img = '/content/normal_resized.png'\n",
        "eval_folder = os.path.join(get_latest_model(),'Evaluation_/content/collage.png')\n",
        "\n",
        "evaluator = evaluate_generation.GenerationEvaluator(base_img, eval_folder)\n",
        "\n",
        "lpips = evaluator.run_lpips()\n",
        "ssim, ms_ssim = evaluator.run_mssim()\n",
        "print(f\"LPIPS: {lpips}\\nSSIM: {ssim}\\nMS-SSIM: {ms_ssim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ds0KPgz6uI-"
      },
      "source": [
        "## Save Harmonizer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZS5yU5U6vkU"
      },
      "outputs": [],
      "source": [
        "# Import files to download zips\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTxipCzy60ge"
      },
      "outputs": [],
      "source": [
        "# Zip the mlruns metrics to analyse\n",
        "!zip -r /content/mlrun.zip /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns\n",
        "files.download(\"/content/mlrun.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "o-IZgTDG610d",
        "outputId": "22b3ae6b-ac81-4099-a3b7-aee0101119c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e8095ae6-b7b6-4b58-8823-ad2ffdf0ae94\", \"best_harmonisation_model.zip\", 36371537)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip the best model analysed based on the mlruns\n",
        "m = get_latest_model()\n",
        "zip_cmd = \"zip -r /content/best_harmonisation_model.zip \" + str(m)\n",
        "os.system(zip_cmd)\n",
        "files.download(\"/content/best_harmonisation_model.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fEUmlAKc7zn"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tip34yzOc8Yo"
      },
      "outputs": [],
      "source": [
        "# Remove the MLFlow runs\n",
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RydIJkA9dDav"
      },
      "outputs": [],
      "source": [
        "# Remove all trained models\n",
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/TrainedModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YrF4bB_dFAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cdd1ec-959c-4287-8cb5-778b95c92f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Remove all images\n",
        "%cd ../..\n",
        "! find . -name \"*.png\" -type f -delete"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hFr4JY6yFHWF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9X4-kKK_1yPx"
      ],
      "name": "Harmonisation Baseline Model - ConSinGAN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}