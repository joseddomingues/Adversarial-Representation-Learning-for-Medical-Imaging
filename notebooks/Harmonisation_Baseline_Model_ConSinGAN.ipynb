{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-EZvBH-LlrR"
      },
      "source": [
        "## Image Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNiTcN3w6pq"
      },
      "source": [
        "Requires that:\n",
        "- malign.png be 3-channel\n",
        "- normal.png be 3-channel\n",
        "- malign_mask.png be one-channel (BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFcbV3kZcJih"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io as img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import torch\n",
        "import subprocess\n",
        "import torchvision as tv\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXoEsj5DDRTx"
      },
      "outputs": [],
      "source": [
        "def get_image_laterality(image):\n",
        "    left_edge = np.sum(image[:, 0])  \n",
        "    right_edge = np.sum(image[:, -1])\n",
        "    return (True, False) if left_edge < right_edge else (False, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdQW6pLMDSnn"
      },
      "outputs": [],
      "source": [
        "def get_measures(image):\n",
        "    positions = np.nonzero(image)\n",
        "    top = positions[0].min()\n",
        "    bottom = positions[0].max()\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    return top, right, bottom, left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W5Yy675DVJ2"
      },
      "outputs": [],
      "source": [
        "def get_start_coordinate(image, mass_path, laterality_r):\n",
        "    imag = cv2.imread(mass_path, cv2.IMREAD_UNCHANGED)\n",
        "    positions = np.nonzero(image)\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    vertical_co = positions[0][list(positions[1]).index(left)]\n",
        "    vertical_co_r = positions[0][list(positions[1]).index(right)]\n",
        "\n",
        "    if laterality_r:\n",
        "        return left, int(vertical_co-imag.shape[1]/2)\n",
        "    else:\n",
        "        return right, int(vertical_co_r-imag.shape[1]/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXNqcyeaDWew"
      },
      "outputs": [],
      "source": [
        "def get_correct_value(number):\n",
        "    if number == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuQQcIOdDXc_"
      },
      "outputs": [],
      "source": [
        "def image_to_binary(image, pth):\n",
        "    b_image = []\n",
        "    for arr in image:\n",
        "        curr = [get_correct_value(elem) for elem in arr]\n",
        "        b_image.append(curr)\n",
        "    b_image = np.array(b_image, dtype=np.uint8)\n",
        "\n",
        "    plt.imsave(pth, np.array(b_image), cmap=cm.gray)\n",
        "    return b_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKbP8PApDcPh"
      },
      "outputs": [],
      "source": [
        "def does_collage_mask(width, height, normal):\n",
        "\n",
        "    normal_image = Image.open(normal)\n",
        "    mass_to_paste = Image.open('malign_aux.png')\n",
        "\n",
        "    # Creates collage and save\n",
        "    back_im = normal_image.copy()\n",
        "    back_im.paste(mass_to_paste, (width,height), mass_to_paste)\n",
        "    \n",
        "    return list(back_im.getdata()) == list(normal_image.getdata())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtPk4p5gDiBj"
      },
      "outputs": [],
      "source": [
        "def is_collage_possible(malign_mask_pth, normal_breast_pth):\n",
        "\n",
        "  # Operations Threshold\n",
        "  threshold = 50\n",
        "\n",
        "  # Read the images\n",
        "  malign_mask = cv2.imread(malign_mask_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  normal_breast = cv2.imread(normal_breast_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  _, normal_x = normal_breast.shape\n",
        "  normal_breast = image_to_binary(normal_breast, 'normal_aux.png')\n",
        "\n",
        "  # Get images laterality\n",
        "  R, _ = get_image_laterality(normal_breast)\n",
        "\n",
        "  # Get images measures\n",
        "  # Calculate malign mass measures\n",
        "  m_top, m_right, m_bottom, m_left = get_measures(malign_mask)\n",
        "\n",
        "  # Calculate normal breast measures\n",
        "  n_top, n_right, n_bottom, n_left = get_measures(normal_breast)\n",
        "\n",
        "  # Calculate widths and heights\n",
        "  malign_mass_width = abs(m_right-m_left)\n",
        "  malign_mass_height = abs(m_bottom-m_top)\n",
        "  normal_breast_width = abs(n_right-n_left)\n",
        "  normal_breast_height = abs(n_bottom-n_top)\n",
        "\n",
        "  # Check if its worth the try\n",
        "  if malign_mass_width > normal_breast_width or malign_mass_height > normal_breast_height:\n",
        "    return -1, -1\n",
        "\n",
        "  # Crop the malign mask\n",
        "  crop_segmentation(malign_mask_pth, 'malign_aux.png')\n",
        "\n",
        "  # Get bottom base coordinate\n",
        "  base_coordinate = get_start_coordinate(normal_breast, 'malign_aux.png', R)\n",
        "\n",
        "  # Coordinate collage starts bottom\n",
        "  c, d = base_coordinate\n",
        "\n",
        "  if R:\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while c < normal_breast.shape[0]:\n",
        "      if does_collage_mask(c, d, 'normal_aux.png'):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c+threshold, d\n",
        "\n",
        "    return -1, -1\n",
        "  else:\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while c > 0:\n",
        "      if does_collage_mask(c, d, 'normal_aux.png'):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c-threshold, d\n",
        "\n",
        "    return -1, -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EvfVGz8cK37"
      },
      "outputs": [],
      "source": [
        "# Remove the 4 channel to collage image\n",
        "def remove_4_channel(im_path, output_path):\n",
        "\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    # Transpose naive image to properly see it\n",
        "    tranposed = img.transpose(2,0,1)\n",
        "\n",
        "    # Transpose image again with only the 3 rgb channels to save\n",
        "    output = tranposed[0:3].transpose(1,2,0)\n",
        "\n",
        "    # Save new naive image (3-channels)\n",
        "    cv2.imwrite(output_path, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGT3kdfwcNzb"
      },
      "outputs": [],
      "source": [
        "# Resize image for hamronisation\n",
        "def resize_image(im_path, percent_original, output_path):\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "    \n",
        "    print('Original Dimensions : ',img.shape)\n",
        "    \n",
        "    scale_percent = percent_original # percent of original size\n",
        "    width = int(img.shape[1] * scale_percent / 100)\n",
        "    height = int(img.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    \n",
        "    # resize image\n",
        "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    print('Resized Dimensions : ',resized.shape)\n",
        "    cv2.imwrite(output_path, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TkjI3EXcMVq"
      },
      "outputs": [],
      "source": [
        "# Make mask have 3 channels\n",
        "def make_3_channels_mask(im_path, out_path):\n",
        "  i = img.imread(im_path)\n",
        "  new_i = []\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i = torch.tensor(np.array(new_i))\n",
        "  tv.io.write_png(new_i, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZX9tjIyXxmQ"
      },
      "outputs": [],
      "source": [
        "# Crops the segmentation by its limits\n",
        "def crop_segmentation(fp, outp):\n",
        "  imag = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
        "  imageObject = Image.open(fp)\n",
        "  positions = np.nonzero(imag)\n",
        "\n",
        "  top = positions[0].min()\n",
        "  bottom = positions[0].max()\n",
        "  left = positions[1].min()\n",
        "  right = positions[1].max()\n",
        "\n",
        "  cropped = imageObject.crop((left,top,right,bottom))\n",
        "  cropped.save(outp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk4uvtD9T-Kz"
      },
      "outputs": [],
      "source": [
        "# Makes a collage given the malign image, the malign mask, and the normal image\n",
        "def make_collage(malign_pth, malign_mask_pth, normal_pth, width, height):\n",
        "\n",
        "  # Reads malign base image\n",
        "  malign = cv2.imread(malign_pth, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Convert mask to 3 channels\n",
        "  make_3_channels_mask(malign_mask_pth, 'malign_mask3.png')\n",
        "  malign_mask = cv2.imread('malign_mask3.png', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Grab the image mask from the mass image\n",
        "  masked = malign.copy()\n",
        "  masked[malign_mask == 0] = 0\n",
        "  cv2.imwrite('segmented_mass.png', masked)\n",
        "\n",
        "  # Crop both the mask, and the masked mass\n",
        "  crop_segmentation('segmented_mass.png', 'cropped_mass.png')\n",
        "  crop_segmentation(malign_mask_pth, 'malign_mask_cropped.png')\n",
        "\n",
        "  normal_image = Image.open(normal_pth)\n",
        "  mass_to_paste = Image.open('cropped_mass.png')\n",
        "  mass_mask = Image.open('malign_mask_cropped.png')\n",
        "\n",
        "  # Creates collage and save\n",
        "  back_im = normal_image.copy()\n",
        "  back_im.paste(mass_to_paste, (width,height), mass_mask)\n",
        "  back_im.save('collage.png', quality=95)\n",
        "\n",
        "  # Creates collage mask\n",
        "  collage_mask = Image.new(\"L\", back_im.size, 0)\n",
        "  collage_mask.paste(mass_mask, (width,height))\n",
        "  collage_mask.save('collage_mask.png', quality=95)\n",
        "\n",
        "  # Deletes unecessary images\n",
        "  try:\n",
        "    os.remove('malign_mask3.png')\n",
        "    os.remove('segmented_mass.png')\n",
        "    os.remove('cropped_mass.png')\n",
        "    os.remove('malign_mask_cropped.png')\n",
        "  except OSError as e:\n",
        "    print(f\"FAILED\\nFile: {e.filename}\\nError: {e.strerror}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBlMM1JrWLb3",
        "outputId": "6eb7a926-4e3a-4a66-8505-6f85690d109e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1048, 997)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w, h = is_collage_possible(malign_mask_pth='malign_mask.png', normal_breast_pth='normal.png')\n",
        "w, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKsyHncdbqI9"
      },
      "outputs": [],
      "source": [
        "make_collage(malign_pth='malign.png', malign_mask_pth='malign_mask.png', normal_pth='normal.png', width=w, height=h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G07f-tcr6LO4"
      },
      "outputs": [],
      "source": [
        "# Crop the collage and mask\n",
        "imag = cv2.imread('collage.png', cv2.IMREAD_UNCHANGED)\n",
        "imageObject = Image.open('collage.png')\n",
        "positions = np.nonzero(imag)\n",
        "\n",
        "top = positions[0].min()\n",
        "bottom = positions[0].max()\n",
        "left = positions[1].min()\n",
        "right = positions[1].max()\n",
        "\n",
        "cropped = imageObject.crop((left,top,right,bottom))\n",
        "cropped.save('new_collage.png')\n",
        "\n",
        "imageObject = Image.open('collage_mask.png')\n",
        "cropped = imageObject.crop((left,top,right,bottom))\n",
        "cropped.save('new_collage_mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KflDw2wG95IH"
      },
      "outputs": [],
      "source": [
        "crop_segmentation('normal.png', 'normal_cropped.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHsKlSIk1_-6"
      },
      "source": [
        "## Harmonizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcUgsHrZ1CMK"
      },
      "source": [
        "### Harmonzer Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R5F5Tzc2qdB",
        "outputId": "9be66ff0-978f-4c90-fb83-3a79e30eb4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN\n"
          ]
        }
      ],
      "source": [
        "# Change to correct directory\n",
        "%cd MedSinGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fgEKbQamS5c"
      },
      "outputs": [],
      "source": [
        "# Make the collage mask 3-channel\n",
        "make_3_channels_mask('collage_mask.png', 'collage_mask3.png')\n",
        "os.remove('collage_mask.png')\n",
        "os.rename('collage_mask3.png', 'collage_mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVMePV2A-Foj"
      },
      "outputs": [],
      "source": [
        "def execute(cmd):\n",
        "    popen = subprocess.Popen(cmd, stdout=subprocess.PIPE, universal_newlines=True)\n",
        "    for stdout_line in iter(popen.stdout.readline, \"\"):\n",
        "        yield stdout_line \n",
        "    popen.stdout.close()\n",
        "    return_code = popen.wait()\n",
        "    if return_code:\n",
        "        raise subprocess.CalledProcessError(return_code, cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "WGuzzV6l2BIZ",
        "outputId": "c21ca96f-86e1-4fdd-9e90-01d408371b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model (TrainedModels/normal/2022_02_03_09_44_38_harmonization_niter_1000_lr_scale_0.1_nstages_3_BN_act_lrelu_0.3)\n",
            "Training model with the following parameters:\n",
            "\t number of stages: 3\n",
            "\t number of concurrently trained stages: 3\n",
            "\t learning rate scaling: 0.1\n",
            "\t non-linearity: lrelu\n",
            "Training on image pyramid: [torch.Size([1, 3, 148, 120]), torch.Size([1, 3, 192, 157]), torch.Size([1, 3, 250, 204])]\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7eba21590f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#    print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-36cd96be24a3>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniversal_newlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstdout_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mstdout_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Normal breast collage Harmonizer creation\n",
        "command = \"python main_train.py --train_mode harmonization --gpu 0 --train_stages 3 --im_min_size 120 --lrelu_alpha 0.3 --niter 1000 --batch_norm --input_name normal.png --naive_img collage.png\"\n",
        "#process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
        "#output, error = process.communicate()\n",
        "#if error:\n",
        "#    print(\"Problem training harmoniser! Terminating...\")\n",
        "#else:\n",
        "#    print(output)\n",
        "\n",
        "for path in execute(command.split()):\n",
        "    print(path, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMNlBMrG1Hmg"
      },
      "source": [
        "### Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jx-vpMU5osX"
      },
      "outputs": [],
      "source": [
        "# Get the latest model\n",
        "def get_latest_model():\n",
        "  base_path = \"TrainedModels/normal_cropped/\"\n",
        "  models = os.listdir(base_path)\n",
        "\n",
        "  latest = 0 # Values will always be bigger than 0\n",
        "  desired = models[0]\n",
        "\n",
        "  for id, model in enumerate(models):\n",
        "    splitted = model.split(\"_\")\n",
        "    code = splitted[:6]\n",
        "    code = int(''.join(code))\n",
        "    if code > latest:\n",
        "      latest = code\n",
        "      desired = model\n",
        "\n",
        "  return os.path.join(base_path, desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AacGNG07vBg",
        "outputId": "ba8a344f-3cd2-48be-f6d0-84f9acfd490c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FINE TUNE\n",
        "m = get_latest_model()\n",
        "fine_tune_cmd = \"python main_train.py --gpu 0 --train_mode harmonization --input_name normal_cropped.png --naive_img new_collage.png --fine_tune --model_dir \" + str(m)\n",
        "os.system(fine_tune_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBaDW1M0gG7u"
      },
      "outputs": [],
      "source": [
        "# FINE TUNE\n",
        "# !python main_train.py --gpu 0 --train_mode harmonization --input_name normal.png --naive_img collage.png --fine_tune --model_dir TrainedModels/normal/2022_01_17_19_51_18_harmonization_niter_1000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjOZzo8S18Z7"
      },
      "source": [
        "### Harmonise The Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WbYrgQoBdzs",
        "outputId": "7d7187cf-c340-48c9-fe82-aa34d326ee01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normal breast collage harmonisation\n",
        "m = get_latest_model()\n",
        "harmonise_cmd = \"python evaluate_model.py --gpu 0 --model_dir \" + str(m) + \" --naive_img new_collage.png\"\n",
        "os.system(harmonise_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR3plhis-83m"
      },
      "outputs": [],
      "source": [
        "# Normal breast collage harmonisation\n",
        "#!python evaluate_model.py --gpu 0 --model_dir TrainedModels/normal/2022_01_17_21_07_38_harmonization_fine-tune_niter_2000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 --naive_img collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBSXbWo5A-Ck"
      },
      "source": [
        "### Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNBvrMZ8DYaG"
      },
      "outputs": [],
      "source": [
        "# Resizes an image to a specific dimension\n",
        "def resize_to_dim(img_pth, width, height, out_pth):\n",
        "  base = cv2.imread(img_pth, cv2.IMREAD_UNCHANGED)\n",
        "  dim = (width, height)\n",
        "  resized = cv2.resize(base, dim)\n",
        "  cv2.imwrite(out_pth, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6zP9J5ZD8sP"
      },
      "outputs": [],
      "source": [
        "resize_to_dim('normal_cropped.png', 204, 250, 'normal_resized.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YlWVtyXBAU8"
      },
      "outputs": [],
      "source": [
        "from MedSinGAN.evaluate_generation import GenerationEvaluator\n",
        "\n",
        "base_img = 'normal_resized.png'\n",
        "eval_folder = os.path.join(get_latest_model(),'Evaluation_new_collage.png')\n",
        "\n",
        "evaluator = GenerationEvaluator(base_img, eval_folder)\n",
        "\n",
        "lpips = evaluator.run_lpips()\n",
        "ssim, ms_ssim = evaluator.run_mssim()\n",
        "print(f\"LPIPS: {lpips}\\nSSIM: {ssim}\\nMS-SSIM: {ms_ssim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ds0KPgz6uI-"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZS5yU5U6vkU"
      },
      "outputs": [],
      "source": [
        "# Zip everything from this model\n",
        "!zip -r current_model.zip ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fEUmlAKc7zn"
      },
      "source": [
        "## Delete Current Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tip34yzOc8Yo"
      },
      "outputs": [],
      "source": [
        "# Delete everything that the model produces\n",
        "! rm -r mlruns TrainedModels"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9X4-kKK_1yPx",
        "QMNlBMrG1Hmg",
        "ZjOZzo8S18Z7",
        "CBSXbWo5A-Ck",
        "6Ds0KPgz6uI-"
      ],
      "name": "Harmonisation Baseline Model - ConSinGAN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
