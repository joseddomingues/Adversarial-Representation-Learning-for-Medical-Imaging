{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X4-kKK_1yPx"
      },
      "source": [
        "## Clone Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1cDHVEb1uOh",
        "outputId": "32965518-693e-430e-8e22-bcda609ac48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Adversarial-Representation-Learning-for-Medical-Imaging'...\n",
            "remote: Enumerating objects: 550, done.\u001b[K\n",
            "remote: Counting objects: 100% (550/550), done.\u001b[K\n",
            "remote: Compressing objects: 100% (392/392), done.\u001b[K\n",
            "remote: Total 550 (delta 315), reused 376 (delta 145), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (550/550), 52.49 MiB | 13.09 MiB/s, done.\n",
            "Resolving deltas: 100% (315/315), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo\n",
        "!git clone https://<DRIVE>@github.com/java-master007/Adversarial-Representation-Learning-for-Medical-Imaging.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UgmJZbs11J7",
        "outputId": "fdd0355f-630d-4225-d5ba-75c31134a234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging\n"
          ]
        }
      ],
      "source": [
        "# Change to the correct directory\n",
        "%cd Adversarial-Representation-Learning-for-Medical-Imaging/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vab1bbrK13JC"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "# It will need restart on colab\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-EZvBH-LlrR"
      },
      "source": [
        "## Image Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNiTcN3w6pq"
      },
      "source": [
        "Requires that:\n",
        "- malign.png be 3-channel\n",
        "- normal.png be 3-channel\n",
        "- malign_mask.png be one-channel (BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KFcbV3kZcJih"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io as img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import torch\n",
        "import torchvision as tv\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CXoEsj5DDRTx"
      },
      "outputs": [],
      "source": [
        "def get_image_laterality(image):\n",
        "    left_edge = np.sum(image[:, 0])  \n",
        "    right_edge = np.sum(image[:, -1])\n",
        "    return (True, False) if left_edge < right_edge else (False, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PdQW6pLMDSnn"
      },
      "outputs": [],
      "source": [
        "def get_measures(image):\n",
        "    positions = np.nonzero(image)\n",
        "    top = positions[0].min()\n",
        "    bottom = positions[0].max()\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    return top, right, bottom, left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_W5Yy675DVJ2"
      },
      "outputs": [],
      "source": [
        "def get_start_coordinate(image, mass_path, laterality_r):\n",
        "    imag = cv2.imread(mass_path, cv2.IMREAD_UNCHANGED)\n",
        "    positions = np.nonzero(image)\n",
        "    left = positions[1].min()\n",
        "    right = positions[1].max()\n",
        "    vertical_co = positions[0][list(positions[1]).index(left)]\n",
        "    vertical_co_r = positions[0][list(positions[1]).index(right)]\n",
        "\n",
        "    if laterality_r:\n",
        "        return left, int(vertical_co-imag.shape[1]/2)\n",
        "    else:\n",
        "        return right, int(vertical_co_r-imag.shape[1]/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mXNqcyeaDWew"
      },
      "outputs": [],
      "source": [
        "def get_correct_value(number):\n",
        "    if number == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kuQQcIOdDXc_"
      },
      "outputs": [],
      "source": [
        "def image_to_binary(image, pth):\n",
        "    b_image = []\n",
        "    for arr in image:\n",
        "        curr = [get_correct_value(elem) for elem in arr]\n",
        "        b_image.append(curr)\n",
        "    b_image = np.array(b_image, dtype=np.uint8)\n",
        "\n",
        "    plt.imsave(pth, np.array(b_image), cmap=cm.gray)\n",
        "    return b_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RKbP8PApDcPh"
      },
      "outputs": [],
      "source": [
        "def does_collage_mask(width, height, normal):\n",
        "\n",
        "    normal_image = Image.open(normal)\n",
        "    mass_to_paste = Image.open('/content/malign_aux.png')\n",
        "\n",
        "    # Creates collage and save\n",
        "    back_im = normal_image.copy()\n",
        "    back_im.paste(mass_to_paste, (width,height), mass_to_paste)\n",
        "    \n",
        "    return list(back_im.getdata()) == list(normal_image.getdata())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GtPk4p5gDiBj"
      },
      "outputs": [],
      "source": [
        "def is_collage_possible(malign_mask_pth, normal_breast_pth):\n",
        "\n",
        "  # Operations Threshold\n",
        "  threshold = 50\n",
        "\n",
        "  # Read the images\n",
        "  malign_mask = cv2.imread(malign_mask_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  normal_breast = cv2.imread(normal_breast_pth, cv2.IMREAD_GRAYSCALE)\n",
        "  _, normal_x = normal_breast.shape\n",
        "  normal_breast = image_to_binary(normal_breast, '/content/normal_aux.png')\n",
        "\n",
        "  # Get images laterality\n",
        "  R, _ = get_image_laterality(normal_breast)\n",
        "\n",
        "  # Get images measures\n",
        "  # Calculate malign mass measures\n",
        "  m_top, m_right, m_bottom, m_left = get_measures(malign_mask)\n",
        "\n",
        "  # Calculate normal breast measures\n",
        "  n_top, n_right, n_bottom, n_left = get_measures(normal_breast)\n",
        "\n",
        "  # Calculate widths and heights\n",
        "  malign_mass_width = abs(m_right-m_left)\n",
        "  malign_mass_height = abs(m_bottom-m_top)\n",
        "  normal_breast_width = abs(n_right-n_left)\n",
        "  normal_breast_height = abs(n_bottom-n_top)\n",
        "\n",
        "  # Check if its worth the try\n",
        "  if malign_mass_width > normal_breast_width or malign_mass_height > normal_breast_height:\n",
        "    return -1, -1\n",
        "\n",
        "  # Crop the malign mask\n",
        "  crop_segmentation(malign_mask_pth, '/content/malign_aux.png')\n",
        "\n",
        "  # Get bottom base coordinate\n",
        "  base_coordinate = get_start_coordinate(normal_breast, '/content/malign_aux.png', R)\n",
        "\n",
        "  # Coordinate collage starts bottom\n",
        "  c, d = base_coordinate\n",
        "\n",
        "  if R:\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while c < normal_breast.shape[0]:\n",
        "      if does_collage_mask(c, d, '/content/normal_aux.png'):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c+threshold, d\n",
        "\n",
        "    return -1, -1\n",
        "  else:\n",
        "\n",
        "    # Go up until the masks match. If never match then skip them\n",
        "    while c > 0:\n",
        "      if does_collage_mask(c, d, '/content/normal_aux.png'):\n",
        "        return c, d\n",
        "\n",
        "      c, d = c-threshold, d\n",
        "\n",
        "    return -1, -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7EvfVGz8cK37"
      },
      "outputs": [],
      "source": [
        "# Remove the 4 channel to collage image\n",
        "def remove_4_channel(im_path, output_path):\n",
        "\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    # Transpose naive image to properly see it\n",
        "    tranposed = img.transpose(2,0,1)\n",
        "\n",
        "    # Transpose image again with only the 3 rgb channels to save\n",
        "    output = tranposed[0:3].transpose(1,2,0)\n",
        "\n",
        "    # Save new naive image (3-channels)\n",
        "    cv2.imwrite(output_path, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PGT3kdfwcNzb"
      },
      "outputs": [],
      "source": [
        "# Resize image for hamronisation\n",
        "def resize_image(im_path, percent_original, output_path):\n",
        "    img = cv2.imread(im_path, cv2.IMREAD_UNCHANGED)\n",
        "    \n",
        "    print('Original Dimensions : ',img.shape)\n",
        "    \n",
        "    scale_percent = percent_original # percent of original size\n",
        "    width = int(img.shape[1] * scale_percent / 100)\n",
        "    height = int(img.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    \n",
        "    # resize image\n",
        "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    print('Resized Dimensions : ',resized.shape)\n",
        "    cv2.imwrite(output_path, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2TkjI3EXcMVq"
      },
      "outputs": [],
      "source": [
        "# Make mask have 3 channels\n",
        "def make_3_channels_mask(im_path, out_path):\n",
        "  i = img.imread(im_path)\n",
        "  new_i = []\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i.append(i)\n",
        "  new_i = torch.tensor(np.array(new_i))\n",
        "  tv.io.write_png(new_i, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bZX9tjIyXxmQ"
      },
      "outputs": [],
      "source": [
        "# Crops the segmentation by its limits\n",
        "def crop_segmentation(fp, outp):\n",
        "  imag = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
        "  imageObject = Image.open(fp)\n",
        "  positions = np.nonzero(imag)\n",
        "\n",
        "  top = positions[0].min()\n",
        "  bottom = positions[0].max()\n",
        "  left = positions[1].min()\n",
        "  right = positions[1].max()\n",
        "\n",
        "  cropped = imageObject.crop((left,top,right,bottom))\n",
        "  cropped.save(outp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pk4uvtD9T-Kz"
      },
      "outputs": [],
      "source": [
        "# Makes a collage given the malign image, the malign mask, and the normal image\n",
        "def make_collage(malign_pth, malign_mask_pth, normal_pth, width, height):\n",
        "\n",
        "  # Reads malign base image\n",
        "  malign = cv2.imread(malign_pth, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Convert mask to 3 channels\n",
        "  make_3_channels_mask(malign_mask_pth, '/content/malign_mask3.png')\n",
        "  malign_mask = cv2.imread('/content/malign_mask3.png', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # Grab the image mask from the mass image\n",
        "  masked = malign.copy()\n",
        "  masked[malign_mask == 0] = 0\n",
        "  cv2.imwrite('/content/segmented_mass.png', masked)\n",
        "\n",
        "  # Crop both the mask, and the masked mass\n",
        "  crop_segmentation('/content/segmented_mass.png', '/content/cropped_mass.png')\n",
        "  crop_segmentation(malign_mask_pth, '/content/malign_mask_cropped.png')\n",
        "\n",
        "  normal_image = Image.open(normal_pth)\n",
        "  mass_to_paste = Image.open('/content/cropped_mass.png')\n",
        "  mass_mask = Image.open('/content/malign_mask_cropped.png')\n",
        "\n",
        "  # Creates collage and save\n",
        "  back_im = normal_image.copy()\n",
        "  back_im.paste(mass_to_paste, (width,height), mass_mask)\n",
        "  back_im.save('/content/collage.png', quality=95)\n",
        "\n",
        "  # Creates collage mask\n",
        "  collage_mask = Image.new(\"L\", back_im.size, 0)\n",
        "  collage_mask.paste(mass_mask, (width,height))\n",
        "  collage_mask.save('/content/collage_mask.png', quality=95)\n",
        "\n",
        "  # Deletes unecessary images\n",
        "  try:\n",
        "    os.remove('/content/malign_mask3.png')\n",
        "    os.remove('/content/segmented_mass.png')\n",
        "    os.remove('/content/cropped_mass.png')\n",
        "    os.remove('/content/malign_mask_cropped.png')\n",
        "  except OSError as e:\n",
        "    print(f\"FAILED\\nFile: {e.filename}\\nError: {e.strerror}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBlMM1JrWLb3",
        "outputId": "24f99997-aae5-41ad-9540-931ae2a6f225"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/normal_aux.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/g7/nkrn8hv17wd0kycz8srzhf7r0000gn/T/ipykernel_1660/2083238835.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_collage_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmalign_mask_pth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/josedaviddomingues/Desktop/Harmoniser_preparation/malign_mask.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_breast_pth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/josedaviddomingues/Desktop/Harmoniser_preparation/normal1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/g7/nkrn8hv17wd0kycz8srzhf7r0000gn/T/ipykernel_1660/4076711143.py\u001b[0m in \u001b[0;36mis_collage_possible\u001b[0;34m(malign_mask_pth, normal_breast_pth)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnormal_breast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_breast_pth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_breast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mnormal_breast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_breast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/normal_aux.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Get images laterality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/g7/nkrn8hv17wd0kycz8srzhf7r0000gn/T/ipykernel_1660/2720862310.py\u001b[0m in \u001b[0;36mimage_to_binary\u001b[0;34m(image, pth)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mb_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mb_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/envs/Adversarial-Representation-Learning-for-Medical-Imaging/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2144\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/envs/Adversarial-Representation-Learning-for-Medical-Imaging/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/envs/Adversarial-Representation-Learning-for-Medical-Imaging/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/normal_aux.png'"
          ]
        }
      ],
      "source": [
        "w, h = is_collage_possible(malign_mask_pth='/Users/josedaviddomingues/Desktop/Harmoniser_preparation/malign_mask.png', normal_breast_pth='/Users/josedaviddomingues/Desktop/Harmoniser_preparation/normal1.png')\n",
        "w, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKsyHncdbqI9"
      },
      "outputs": [],
      "source": [
        "make_collage(malign_pth='/content/malign.png', malign_mask_pth='/content/malign_mask.png', normal_pth='/content/normal.png', width=1000, height=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G07f-tcr6LO4"
      },
      "outputs": [],
      "source": [
        "# Crop the collage and mask\n",
        "imag = cv2.imread('/content/collage.png', cv2.IMREAD_UNCHANGED)\n",
        "imageObject = Image.open('/content/collage.png')\n",
        "positions = np.nonzero(imag)\n",
        "\n",
        "top = positions[0].min()\n",
        "bottom = positions[0].max()\n",
        "left = positions[1].min()\n",
        "right = positions[1].max()\n",
        "\n",
        "cropped = imageObject.crop((left,top,right,bottom))\n",
        "cropped.save('/content/new_collage.png')\n",
        "\n",
        "imageObject = Image.open('/content/collage_mask.png')\n",
        "cropped = imageObject.crop((left,top,right,bottom))\n",
        "cropped.save('/content/new_collage_mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KflDw2wG95IH"
      },
      "outputs": [],
      "source": [
        "crop_segmentation('/content/normal.png', '/content/normal_cropped.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHsKlSIk1_-6"
      },
      "source": [
        "## Harmonizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcUgsHrZ1CMK"
      },
      "source": [
        "### Harmonzer Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R5F5Tzc2qdB",
        "outputId": "38dfaebb-5100-4c11-8ea6-8a91f7f276a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN\n"
          ]
        }
      ],
      "source": [
        "# Change to correct directory\n",
        "%cd MedSinGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fgEKbQamS5c"
      },
      "outputs": [],
      "source": [
        "# Make the collage mask 3-channel\n",
        "make_3_channels_mask('/content/new_collage_mask.png', '/content/collage_mask3.png')\n",
        "os.remove('/content/new_collage_mask.png')\n",
        "os.rename('/content/collage_mask3.png', '/content/new_collage_mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGuzzV6l2BIZ",
        "outputId": "8b0afb0e-11e5-48d3-8c96-08589567276c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model (TrainedModels/normal_cropped/2022_01_31_16_48_31_harmonization_niter_1000_lr_scale_0.1_nstages_3_BN_act_lrelu_0.3)\n",
            "Training model with the following parameters:\n",
            "\t number of stages: 3\n",
            "\t number of concurrently trained stages: 3\n",
            "\t learning rate scaling: 0.1\n",
            "\t non-linearity: lrelu\n",
            "Training on image pyramid: [torch.Size([1, 3, 210, 120]), torch.Size([1, 3, 230, 131]), torch.Size([1, 3, 250, 143])]\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
            "  FutureWarning,\n",
            "stage [0/2]:: 100% 1000/1000 [07:20<00:00,  2.27it/s]\n",
            "stage [1/2]:: 100% 1000/1000 [08:02<00:00,  2.07it/s]\n",
            "stage [2/2]:: 100% 1000/1000 [08:54<00:00,  1.87it/s]\n",
            "Time for training: 1466.4994146823883 seconds\n"
          ]
        }
      ],
      "source": [
        "# Normal breast collage Harmonizer creation\n",
        "!python main_train.py --train_mode harmonization --gpu 0 --train_stages 3 --im_min_size 120 --lrelu_alpha 0.3 --niter 1000 --batch_norm --input_name /content/normal_cropped.png --naive_img /content/new_collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMNlBMrG1Hmg"
      },
      "source": [
        "### Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jx-vpMU5osX"
      },
      "outputs": [],
      "source": [
        "# Get the latest model\n",
        "def get_latest_model():\n",
        "  base_path = \"TrainedModels/normal_cropped/\"\n",
        "  models = os.listdir(base_path)\n",
        "\n",
        "  latest = 0 # Values will always be bigger than 0\n",
        "  desired = models[0]\n",
        "\n",
        "  for id, model in enumerate(models):\n",
        "    splitted = model.split(\"_\")\n",
        "    code = splitted[:6]\n",
        "    code = int(''.join(code))\n",
        "    if code > latest:\n",
        "      latest = code\n",
        "      desired = model\n",
        "\n",
        "  return os.path.join(base_path, desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AacGNG07vBg",
        "outputId": "ba8a344f-3cd2-48be-f6d0-84f9acfd490c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FINE TUNE\n",
        "m = get_latest_model()\n",
        "fine_tune_cmd = \"python main_train.py --gpu 0 --train_mode harmonization --input_name /content/normal_cropped.png --naive_img /content/new_collage.png --fine_tune --model_dir \" + str(m)\n",
        "os.system(fine_tune_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBaDW1M0gG7u"
      },
      "outputs": [],
      "source": [
        "# FINE TUNE\n",
        "# !python main_train.py --gpu 0 --train_mode harmonization --input_name /content/normal.png --naive_img /content/collage.png --fine_tune --model_dir TrainedModels/normal/2022_01_17_19_51_18_harmonization_niter_1000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjOZzo8S18Z7"
      },
      "source": [
        "### Harmonise The Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WbYrgQoBdzs",
        "outputId": "7d7187cf-c340-48c9-fe82-aa34d326ee01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normal breast collage harmonisation\n",
        "m = get_latest_model()\n",
        "harmonise_cmd = \"python evaluate_model.py --gpu 0 --model_dir \" + str(m) + \" --naive_img /content/new_collage.png\"\n",
        "os.system(harmonise_cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR3plhis-83m"
      },
      "outputs": [],
      "source": [
        "# Normal breast collage harmonisation\n",
        "#!python evaluate_model.py --gpu 0 --model_dir TrainedModels/normal/2022_01_17_21_07_38_harmonization_fine-tune_niter_2000_lr_scale_0.1_nstages_8_BN_act_lrelu_0.3 --naive_img /content/collage.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBSXbWo5A-Ck"
      },
      "source": [
        "### Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNBvrMZ8DYaG"
      },
      "outputs": [],
      "source": [
        "# Resizes an image to a specific dimension\n",
        "def resize_to_dim(img_pth, width, height, out_pth):\n",
        "  base = cv2.imread(img_pth, cv2.IMREAD_UNCHANGED)\n",
        "  dim = (width, height)\n",
        "  resized = cv2.resize(base, dim)\n",
        "  cv2.imwrite(out_pth, resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6zP9J5ZD8sP"
      },
      "outputs": [],
      "source": [
        "resize_to_dim('/content/normal_cropped.png', 204, 250, '/content/normal_resized.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YlWVtyXBAU8"
      },
      "outputs": [],
      "source": [
        "import evaluate_generation\n",
        "\n",
        "base_img = '/content/normal_resized.png'\n",
        "eval_folder = os.path.join(get_latest_model(),'Evaluation_/content/new_collage.png')\n",
        "\n",
        "evaluator = evaluate_generation.GenerationEvaluator(base_img, eval_folder)\n",
        "\n",
        "lpips = evaluator.run_lpips()\n",
        "ssim, ms_ssim = evaluator.run_mssim()\n",
        "print(f\"LPIPS: {lpips}\\nSSIM: {ssim}\\nMS-SSIM: {ms_ssim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ds0KPgz6uI-"
      },
      "source": [
        "## Save Harmonizer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZS5yU5U6vkU"
      },
      "outputs": [],
      "source": [
        "# Import files to download zips\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "XTxipCzy60ge",
        "outputId": "74372ce4-cf0d-4a01-cb58-8c72ff292b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/meta.yaml (deflated 17%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Generator Train Loss Reconstruction (deflated 54%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Discriminator Train Loss Gradient Penalty (deflated 55%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Generator Train Loss (deflated 53%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Discriminator Train Loss Real (deflated 53%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/metrics/Discriminator Train Loss Fake (deflated 52%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/artifacts/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/meta.yaml (deflated 41%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.user (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.source.git.commit (deflated 3%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/tags/mlflow.source.name (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/ (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/Train Depth (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/Learning Scale Rate (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/Activation Function (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/N Training Stages (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/0/da70c235addf4ed8884578ec8c5f2e36/params/N Iterations (stored 0%)\n",
            "  adding: content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns/.trash/ (stored 0%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d9a99dd9-1a69-43d3-8d7a-1773452a9f7d\", \"mlrun.zip\", 11484)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Zip the mlruns metrics to analyse\n",
        "!zip -r /content/mlrun.zip /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns\n",
        "files.download(\"/content/mlrun.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "o-IZgTDG610d",
        "outputId": "e9c39899-bf33-40f2-a379-c67b87fb8a8d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0d7569a6-f3e8-4f99-966c-77ef7475cc95\", \"best_harmonisation_model.zip\", 111599141)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Zip the best model analysed based on the mlruns\n",
        "m = get_latest_model()\n",
        "zip_cmd = \"zip -r /content/best_harmonisation_model.zip \" + str(m)\n",
        "os.system(zip_cmd)\n",
        "files.download(\"/content/best_harmonisation_model.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fEUmlAKc7zn"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tip34yzOc8Yo"
      },
      "outputs": [],
      "source": [
        "# Remove the MLFlow runs\n",
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/mlruns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RydIJkA9dDav"
      },
      "outputs": [],
      "source": [
        "# Remove all trained models\n",
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSinGAN/TrainedModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YrF4bB_dFAz"
      },
      "outputs": [],
      "source": [
        "# Remove all images\n",
        "! find . -name \"*.png\" -type f -delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcjWDV8lbgXR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6Ds0KPgz6uI-",
        "0fEUmlAKc7zn"
      ],
      "name": "Harmonisation Baseline Model - ConSinGAN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
