{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline Model - UNet",
      "provenance": [],
      "collapsed_sections": [
        "0q0Wi35MkR9g",
        "BM-VsA1dNNiB",
        "USI9wG8G0RnH",
        "gOUMtetBhAph",
        "0PZ7DpaG-Xa3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q0Wi35MkR9g"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5QQKxc5s9rb"
      },
      "source": [
        "# Clone the repo\n",
        "!git clone https://<TOKEN>@github.com/java-master007/Adversarial-Representation-Learning-for-Medical-Imaging.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X9ZmUipvbyw",
        "outputId": "f3fc68bb-cf7f-4b12-a90e-7c16e79834c2"
      },
      "source": [
        "# Change to correct folder\n",
        "%cd Adversarial-Representation-Learning-for-Medical-Imaging/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Adversarial-Representation-Learning-for-Medical-Imaging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! git checkout feature/new-unet-training"
      ],
      "metadata": {
        "id": "d9KloqDATzyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65yfRG9LyBBZ"
      },
      "source": [
        "# Install requirements\n",
        "# Might need to restart on colab\n",
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM-VsA1dNNiB"
      },
      "source": [
        "## Segmentation Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiThmFk6wIqW"
      },
      "source": [
        "%cd MedSegmentation/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_Unet.py --train_folder /content/Adversarial-Representation-Learning-for-Medical-Imaging/data --val_folder /content/Adversarial-Representation-Learning-for-Medical-Imaging/data --n_epochs 200 --batch_size 1"
      ],
      "metadata": {
        "id": "WBkM9fxjVXGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing different combinations for segmentation\n",
        "# number of iterations, learning rate, batch size.\n",
        "import os\n",
        "\n",
        "iters = [1000, 2000, 4000, 6000, 8000]\n",
        "lr = [0.01, 0.05]\n",
        "batch = [1,2,3]\n",
        "\n",
        "for i in iters:\n",
        "  for l in lr:\n",
        "    for b in batch:\n",
        "      os.system(\"python train_Unet.py --train_folder /content/drive/MyDrive/Thesis/validationData --val_folder /content/drive/MyDrive/Thesis/validationData --model_checkpoints model_checkpoints_niter_{0}_lr_{1}_batch_{2} --optimizer_checkpoints model_optimizers_niter_{3}_lr_{4}_batch_{5} --experiment_name Experiment_niter_{9}_lr_{10}_batch_{11} --n_epochs {12} --l_rate {13} --batch_size {14}\".format(i,l,b,i,l,b,i,l,b,i,l,b))"
      ],
      "metadata": {
        "id": "vqJLTQ-vR6to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment Images With Saved Model"
      ],
      "metadata": {
        "id": "L5xz7c_M26pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MedSegmentation/"
      ],
      "metadata": {
        "id": "QiefW071_jH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4uAF46lqtZ"
      },
      "source": [
        "! python api.py --model_dir /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/model_checkpoints --test_images /content/Adversarial-Representation-Learning-for-Medical-Imaging/images --no_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USI9wG8G0RnH"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import files to download zips\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "eArCH-4l3Pin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the mlruns metrics to analyse\n",
        "!zip -r /content/mlrun.zip /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/mlruns\n",
        "files.download(\"/content/mlrun.zip\")"
      ],
      "metadata": {
        "id": "3gbQHAT3K_63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTwOt56E04Du"
      },
      "source": [
        "# Zip the best model analysed based on the mlruns\n",
        "!zip -r /content/best_segmentation_model.zip /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/model_checkpoints\n",
        "files.download(\"/content/best_segmentation_model.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the segmentation results and download\n",
        "!zip -r /content/malign-tests-segmentation.zip /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/results\n",
        "files.download(\"/content/malign-tests-segmentation.zip\")"
      ],
      "metadata": {
        "id": "yNpCMajH_3ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOUMtetBhAph"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUtiqp0BpYZL"
      },
      "source": [
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/results"
      ],
      "metadata": {
        "id": "RA96fFzFANQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/graphs_unet"
      ],
      "metadata": {
        "id": "A7f-Z3CNJV5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/mlruns"
      ],
      "metadata": {
        "id": "7AxUPO8eJZOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/model_checkpoints"
      ],
      "metadata": {
        "id": "CEUy1ziaJZDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/model_optimizers"
      ],
      "metadata": {
        "id": "OyQs4ij2JY3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "0PZ7DpaG-Xa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "import os\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "def dice_coeff(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Calculates the dice coefficient for the images\n",
        "    @param y_true: The ground truth mask\n",
        "    @param y_pred: The predicted mask\n",
        "    @param smooth:\n",
        "    @return: The Dice Coefficient value\n",
        "    \"\"\"\n",
        "\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true) + K.sum(y_pred)\n",
        "    dice = K.mean((2. * intersection + smooth) / (union + smooth))\n",
        "    return K.get_value(dice)\n",
        "\n",
        "\n",
        "def jaccard_index(y_true, y_pred, smooth=1):\n",
        "    \"\"\"\n",
        "    Performs jaccard index using jaccard score from scikit learn\n",
        "    @param smooth:\n",
        "    @param y_true: The true ground truth value\n",
        "    @param y_pred: The predicted value\n",
        "    @return: The Jaccard score between the two images\n",
        "    \"\"\"\n",
        "\n",
        "    intersection = K.sum(K.abs(y_true * y_pred))\n",
        "    union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
        "    iou = K.mean((intersection + smooth) / (union + smooth))\n",
        "    return K.get_value(iou)\n",
        "\n",
        "def bce_metric(y_true, y_pred):\n",
        "  loss = torch.nn.BCELoss()\n",
        "  return loss(y_pred, y_true)"
      ],
      "metadata": {
        "id": "-Id-6w0NBPTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average metric results\n",
        "dice = 0\n",
        "jacc = 0\n",
        "pred_folder = '/content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/results'\n",
        "or_folder = '/content/drive/MyDrive/Thesis/seg_masks'\n",
        "for i in os.listdir(or_folder):\n",
        "  t = cv2.imread(os.path.join(or_folder, i), 0)\n",
        "  p = cv2.imread(os.path.join(pred_folder, i), 0)\n",
        "\n",
        "  t = t.reshape((t.shape[0], t.shape[1], 1)).transpose((2, 0, 1)).astype(float)/255\n",
        "  p = p.reshape((p.shape[0], p.shape[1], 1)).transpose((2, 0, 1)).astype(float)/255\n",
        "\n",
        "  dice += dice_coeff(t, p)\n",
        "  jacc += jaccard_index(t, p)\n",
        "\n",
        "print(\"Dice Coefficient:\", dice/len(os.listdir(or_folder)))\n",
        "print(\"Jaccard Index:\", jacc/len(os.listdir(or_folder)))"
      ],
      "metadata": {
        "id": "-55UABXt-YOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2d6af5-418a-4446-aa60-7d535a9cd44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice Coefficient: 0.03548681480820949\n",
            "Jaccard Index: 0.018242735536328245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = cv2.imread('/content/Adversarial-Representation-Learning-for-Medical-Imaging/MedSegmentation/results/1_mask.png', 0)\n",
        "t = cv2.imread('/content/drive/MyDrive/Thesis/trainingData/1/1_1_mask.png', 0)\n",
        "\n",
        "print(p.shape)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ns70aU1SWbv",
        "outputId": "7abbc760-a6cd-4663-962c-723b3c7dfee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2457, 1996)\n",
            "(2457, 1996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = torch.tensor(p, dtype=torch.float)/255\n",
        "t = torch.tensor(t, dtype=torch.float)/255"
      ],
      "metadata": {
        "id": "hfq966VqS5d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bce_metric(t,p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQWoLBNHS9i_",
        "outputId": "8af6bbff-c56a-4ccb-d0d9-3bbb083176c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3023)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dice_coeff(t,p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9lUO7Q6TVHh",
        "outputId": "729d191a-538f-461e-e289-3a0eb46d1ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.032773282"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "kCp65eydVklx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = cv2.imread('/content/Adversarial-Representation-Learning-for-Medical-Imaging/data/1/1.png')"
      ],
      "metadata": {
        "id": "-9DomiV8z63F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "Y9SNo3Etz_FN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}